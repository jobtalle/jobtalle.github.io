<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-109031298-1"></script><script src="js/google.js"></script><title>Job Talle | Layered voxel rendering</title><meta charset="UTF-8"><meta name="description" content="...."/><meta name="keywords" content="software development, AI, algorithms, programming, Job Talle"/><meta name="author" content="Job Talle"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:locale" content="en_US"/><meta property="og:title" content="Layered voxel rendering"/><meta property="og:url" content="https://jobtalle.com/layered_voxel_rendering.html"/><meta property="og:description" content="...."/><meta property="og:image" content="https://jobtalle.com/posts/2019_11_10/img/preview.jpg"/><meta property="twitter:image" content="https://jobtalle.com/posts/2019_11_10/img/preview.jpg"/><meta property="twitter:description" content="...."/><meta property="twitter:site" content="jobtalle.com"/><meta property="twitter:card" content="summary"/><meta property="twitter:title" content="Layered voxel rendering"/><link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet"/><link rel="shortcut icon" type="image/gif" href="img/favicon.gif"/><link rel="stylesheet" type="text/css" href="css/style.css"/></head><body><div id="container"><div id="menu-wrapper"><div id="menu-buttons"><a href="index.html"><div class="menu-button">Blog</div></a><a href="sketches.html"><div class="menu-button">Sketches</div></a><a href="about.html"><div class="menu-button">About</div></a><a href="contact.html"><div class="menu-button">Contact</div></a></div></div><div id="wrapper" class="container"><div id="header"><h1>Job Talle</h1><h2>On software development, AI & Algorithms</h2></div><div id="content"><h1>Layered voxel rendering</h1><span class="date">10 Nov 2019</span><h2>Layered voxel rendering</h2><p>Three dimensional images can be stored using <em>voxels</em>. Voxels are effectively three dimensional pixels. Contrary to common 3D models that store scenes as large collections of triangular planes, voxels can encode volume as well. Additionally, their detail is equal for every part of the scene. The drawbacks however are numerous:</p><ul>    <li>Voxels take up a lot of storage space. Storing colors and surface data of volume interiors that will likely never be rendered need to be stored regardless.</li>    <li>Rendering voxels is slow. Rendering ten thousands of triangles is very doable on modern hardware, but a typical voxel scene has many more voxels than triangles. Also, voxels are often rendered as little cubes consisting of multiple triangles, which makes rendering even slower.</li>    <li>Voxel models are not infinitely precise, so the angle of a surface is hard to determine. If one would zoom in on a 2D pixel image for example, no edge will have a smooth angle. The angle of three dimensional surfaces is however very important to calculate the interaction with light sources in a scene. Without accurate surface angles, shading will not work properly.</li></ul><figure title="A rendered scene">    <img src="posts/2019_11_10/img/island.jpg">    <figcaption>Figure 1: A rendered voxel scene.</figcaption></figure><p>In this article, I propose a real-time voxel rendering method called <em>layered voxel rendering</em>, while trying to tackle these issues. Additionally, an interactive real-time javascript renderer is demonstrated using three different rendering methods. A procedural island generator is used to provide scenes for the renderers. Figure 1 shows a procedurally generated island rendered using the included renderer. The island generator itself is explained in the appendix.</p><p>The rendering method supports</p><ul>    <li>real time voxel rendering at reasonable speed,</li>    <li>a way to store scenes without storing every voxel in it,</li>    <li>and a lighting model that does not require normals to be calculated while rendering.</li></ul><figure title="Voxel layers">    <img src="posts/2019_11_10/img/layers.png">    <figcaption>Figure 2: Stacked images as voxel scene layers.</figcaption></figure><h2>Voxel layers</h2><p>The voxel scene that needs to be rendered is first split up in layers; for every vertical layer of voxels, a <em>slice</em> is created, containing all voxels at that layer. The result is a two dimensional image per layer. Every slice is simply an image. When rendering, these images are drawn from the bottom to the top. Figure 2 shows a schematic of a rendered scene, where layers are used to compose a three dimensional image.</p><p>Note that all images are scaled down vertically. This scale changes the camera pitch angle; scaling down further points the camera more towards the direction of the horizon. To rotate the scene, all images are rotated along the vertical axis before scaling is applied.</p><p></p><h2>Representing a scene</h2><p>The voxel scene will be represented using <em>primitive shapes</em>, and, for the sake of the island example, a heightmap shape to represent the terrain. It is clearer and simpler to populate a scene with shapes than voxels. This representation is also much more compact than storing every voxel in the scene. To be able to make the island shown in Figure 1, the following shapes are needed:</p><ul>    <li>A heightmap to render the terrain.</li>    <li>Cones to render the trees and roofs.</li>    <li>Cylinders to render the huts.</li></ul><p>The trees in the scene are rendered using cones with a <em>voxel density</em> parameter; this makes the shapes not fully solid. The lower the density, the more voxels are omitted. This creates an effect that works well for plants and trees.</p><p>Each shape in the scene has a <em>bounding box</em>, which is a three dimensional box encompassing the shape. For every coordinate inside this box, the shape object will tell whether a voxel exists there. If a voxel exists, the object returns the voxel for that coordinate.</p><p>As mentioned in the first section, lighting and shading can be tricky when rendering voxels. To make it fast and accurate, I pre-shade the voxels; when a shape is sampled and when it returns a voxel, it returns a color with shading applied to it. To shade a voxel, the surface angle of that voxel is required. Shapes always give their voxels the surface normal <em>of the nearest surface</em>. Since it is possible to "peek between the layers" (see Figure 2), occluded voxels must still have the color and shading associated with their nearest surface area to prevent ugly rendering artifacs, since they may be partially visible.</p><h2>Translating scenes into layers</h2><p>Once shapes are properly defined, creating layers is straightforward:</p><ol>    <li>A region to "voxelize" is chosen. Parts of the scene may be omitted, or a scene can be broken up into multiple blocks of layers to make sure not everything needs to be rendered all the time.</li>    <li>A number of layers (which are just images) equal to the height of the render area is created.</li>    <li>For every pixel on every image, the voxel for that coordinate is queried and rendered to its layer.</li></ol><p>Once the layers are created, they can be sent to the renderer to produce the complete and interactive voxel scene.</p><h2>An interactive renderer</h2>
<h2>Rendering methods</h2><p>Rendering transformed images is pretty easy, but there are different ways to go about it. I implemented three renderers to compare their performance.</p><ol>    <li>Since I render my layers on canvases in javascript, a <em>canvas renderer</em> is the most obvious choice. This renderer is quite performant compared to the others, since canvas rendering is GPU accelerated on modern browsers.</li>    <li>A <em>WebGL renderer</em> is also included. I'm using the <a href="https://github.com/jobtalle/myr.js" target="_blank">myr.js</a> library, which uses WebGL 2. Converting canvas pixels to WebGL textures takes some time, because all data needs to be copied over. Once the renderer runs, I don't see much difference in performance compared to the canvas renderer. Note that this option only appears in the example above if your browser supports WebGL 2.</li>    <li>Finally, I implemented a <em>CSS renderer</em>. Here, every layer is instantiated as an HTML element and transformed using CSS transforms. On most browsers, this method is by far the slowest. To my surprise however, it was very performant on Microsoft Edge, in some instances even faster than both the canvas and WebGL renderers on other browsers. I cannot explain this.</li></ol><p>Because all the renderers need to do is rendering transformed images, they all produce the same image quality. When implementing this technique, the method that runs best on the target platform should be chosen.</p><h2>Conclusion</h2><p>The proposed method has some drawbacks:</p><ul>    <li>The camera pitch angle must be within a certain range. If the camera is pitched horizontally enough, you can see too far under the vertical layers. Voxels that should not be seen are then revealed, creating a horizontally sliced image.</li></ul><h2>Appendix: procedurally generating islands</h2><div id="references"><a href="convolutional_textures.html" title="Previously: Convolutional textures"><div class="post-reference post-reference-left">Convolutional textures</div></a></div></div><div id="footer">&copy Job Talle 2017 - 2019</div><div id="icons"><a href="contact.html"><div class="icon" id="icon-mail" title="Mail"></div></a><a href="https://www.github.com/jobtalle" target="_blank"><div class="icon" id="icon-github" title="Github"></div></a><a href="https://twitter.com/jobtalle" target="_blank"><div class="icon" id="icon-twitter" title="Twitter"></div></a><a href="https://www.linkedin.com/in/job-talle-b2b582aa" target="_blank"><div class="icon" id="icon-linkedin" title="LinkedIn"></div></a></div></div></div></body></html>